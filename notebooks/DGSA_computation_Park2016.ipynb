{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses the dataset of Park et al. (2016) to illustrate how to compute DGSA sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide inputs and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter data shape: (1000, 15)\n",
      "Parameter names: ['oilvis', 'dtmax', 'kvkh', 'mflt1', 'mflt2', 'mflt3', 'mflt4', 'oilexp', 'owc', 'sorw', 'swc', 'watexp', 'scen', 'prop', 'size']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the system path\n",
    "root_path = Path.cwd().parent\n",
    "sys.path.append(str(root_path / \"src\"))\n",
    "\n",
    "# Provide the case name (name model parameter and response data files as case_name_parameters.csv and case_name_responses.csv)\n",
    "case_name = \"Park2016\"\n",
    "# Load model parameter data\n",
    "df_parameters = pd.read_csv(root_path / 'data' / f'{case_name}_parameters.csv')\n",
    "print(f\"Model parameter data shape: {df_parameters.shape}\")\n",
    "parameter_values = df_parameters.to_numpy()\n",
    "# extract parameter names from csv header\n",
    "parameter_names = df_parameters.columns.tolist()\n",
    "print(f\"Parameter names: {parameter_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform kmedoids clustering on the model responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Compute an euclidean distance matrix of model responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computation.kmedoids import kmedoids\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load model response data\n",
    "df_responses = pd.read_csv(root_path / 'data' / f'{case_name}_responses.csv')\n",
    "print(f\"Model response data shape: {df_responses.shape}\")\n",
    "response_values = df_responses.to_numpy()\n",
    "\n",
    "# Normalize response values using the min-max method\n",
    "scaler = MinMaxScaler()\n",
    "response_values_scaled = scaler.fit_transform(response_values)\n",
    "\n",
    "# Compute euclidean distance matrix\n",
    "distance_matrix = euclidean_distances(response_values_scaled)\n",
    "print(f\"Distance matrix shape: {distance_matrix.shape}\")\n",
    "\n",
    "# Perform k-medoids clustering\n",
    "clustering = kmedoids(\n",
    "    distance_matrix = distance_matrix, # precomputed distance matrix\n",
    "    n_clusters = 3, # number of clusters\n",
    "    n_rep = 5, # number of k-medoid runs to perform\n",
    "    max_iterations = 50, # maximum number of iterations per run\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Provide a distance matrix of model responses (to allow for user specified distance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (1000, 1000)\n",
      "minDist 3169464336.82, iter 1\n",
      "Kmedoids clustering completed\n"
     ]
    }
   ],
   "source": [
    "from computation.kmedoids import kmedoids\n",
    "\n",
    "# Load distance matrix\n",
    "df_distance_matrix = pd.read_csv(root_path / 'data' / f'{case_name}_distance_matrix.csv',header=None)\n",
    "distance_matrix = df_distance_matrix.to_numpy()\n",
    "print(f\"Distance matrix shape: {distance_matrix.shape}\")\n",
    "\n",
    "# Perform k-medoids clustering\n",
    "clustering = kmedoids(\n",
    "    distance_matrix = distance_matrix, # precomputed distance matrix\n",
    "    n_clusters = 3, # number of clusters\n",
    "    n_rep = 5, # number of k-medoid runs to perform\n",
    "    max_iterations = 50, # maximum number of iterations per run\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the single parameter sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed single parameter sensitivity analysis using the l1norm_and_ASL method\n"
     ]
    }
   ],
   "source": [
    "from computation.single_parameter_sensitivity import single_parameter_sensitivity\n",
    "\n",
    "single_sensitivity = single_parameter_sensitivity(\n",
    "    parameter_values = parameter_values, # model parameter values\n",
    "    clustering = clustering, # clustering results from k-medoids\n",
    "    alpha = 0.95, # significance level\n",
    "    n_draws = 3000, # number of bootstrap draws\n",
    "    random_seed = 100, # random seed for bootstrap sampling\n",
    "    method = 'l1norm_and_ASL' # sensitivity analysis method\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute single parameter sensitivity for three different alphas (for confidence interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed single parameter sensitivity analysis using the l1norm method\n",
      "Completed single parameter sensitivity analysis using the l1norm method\n",
      "Completed single parameter sensitivity analysis using the l1norm method\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from computation.single_parameter_sensitivity import single_parameter_sensitivity\n",
    "\n",
    "alpha_list = [0.95, 0.91, 0.99] # list of significance levels in the order of medium, low, high\n",
    "sensitivity_list = []\n",
    "for alpha in alpha_list:\n",
    "    single_sensitivity_iter = single_parameter_sensitivity(\n",
    "        parameter_values = parameter_values, # model parameter values\n",
    "        clustering = clustering, # clustering results from k-medoids\n",
    "        alpha = alpha, # significance level\n",
    "        n_draws = 3000, # number of bootstrap draws\n",
    "        random_seed = 100, # random seed for bootstrap sampling\n",
    "        method = 'l1norm' # sensitivity analysis method\n",
    "        )\n",
    "\n",
    "    sensitivity_list.append(single_sensitivity_iter['single_l1norm']['standardized'])\n",
    "\n",
    "# convert to 2D array (n_parameters, n_alphas)\n",
    "single_sensitivity_3alphas = np.vstack(sensitivity_list).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the conditional parameter sensitivity (two-way parameter interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sensitivity conditioned on oilvis...\n",
      "Computing sensitivity conditioned on dtmax...\n",
      "Computing sensitivity conditioned on kvkh...\n",
      "Computing sensitivity conditioned on mflt1...\n",
      "Computing sensitivity conditioned on mflt2...\n",
      "Computing sensitivity conditioned on mflt3...\n",
      "Computing sensitivity conditioned on mflt4...\n",
      "Computing sensitivity conditioned on oilexp...\n",
      "Computing sensitivity conditioned on owc...\n",
      "Computing sensitivity conditioned on sorw...\n",
      "Computing sensitivity conditioned on swc...\n",
      "Computing sensitivity conditioned on watexp...\n",
      "Computing sensitivity conditioned on scen...\n",
      "Computing sensitivity conditioned on prop...\n",
      "Computing sensitivity conditioned on size...\n",
      "Completed conditional parameter sensitivity analysis using the l1norm_and_ASL method\n"
     ]
    }
   ],
   "source": [
    "from computation.conditional_parameter_sensitivity import conditional_parameter_sensitivity\n",
    "\n",
    "conditional_sensitivity = conditional_parameter_sensitivity(\n",
    "    parameter_values = parameter_values, # model parameter values\n",
    "    parameter_names = parameter_names, # model parameter names\n",
    "    clustering = clustering, # clustering results from k-medoids\n",
    "    alpha = 0.95, # significance level\n",
    "    n_bins = 3, # number of bins for conditioning\n",
    "    n_draws = 3000, # number of bootstrap draws\n",
    "    random_seed = 100, # random seed for bootstrap sampling\n",
    "    method = 'l1norm_and_ASL' # sensitivity analysis method\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DGSA_save_load import DGSA_save\n",
    "# Combine results\n",
    "DGSA_results = {}\n",
    "DGSA_results['single_l1norm'] = single_sensitivity['single_l1norm']\n",
    "DGSA_results['single_ASL'] = single_sensitivity['single_ASL']\n",
    "DGSA_results['single_l1norm_standardized_3alphas'] = single_sensitivity_3alphas\n",
    "DGSA_results['conditional_l1norm'] = conditional_sensitivity['conditional_l1norm']\n",
    "DGSA_results['conditional_ASL'] = conditional_sensitivity['conditional_ASL']\n",
    "DGSA_results['distance_matrix'] = distance_matrix\n",
    "DGSA_results['clustering'] = clustering\n",
    "DGSA_results['parameter_names'] = parameter_names\n",
    "\n",
    "# Save results\n",
    "DGSA_save(DGSA_results, root_path / 'results' / f'{case_name}_DGSA_results.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
